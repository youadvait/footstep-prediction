#include "PluginProcessor.h"
#include "PluginEditor.h"

FootstepDetectorAudioProcessor::FootstepDetectorAudioProcessor()
#ifndef JucePlugin_PreferredChannelConfigurations
    : AudioProcessor (BusesProperties()
                     #if ! JucePlugin_IsMidiEffect
                      #if ! JucePlugin_IsSynth
                       .withInput  ("Input",  juce::AudioChannelSet::stereo(), true)
                      #endif
                       .withOutput ("Output", juce::AudioChannelSet::stereo(), true)
                     #endif
                     ),
#else
    :
#endif
    parameters (*this, nullptr, juce::Identifier ("FootstepDetector"),
    {
        std::make_unique<juce::AudioParameterFloat> ("sensitivity", "Sensitivity", 0.0f, 1.0f, 0.7f),
        std::make_unique<juce::AudioParameterFloat> ("enhancement", "Enhancement", 1.0f, 1.4f, 1.15f),
        std::make_unique<juce::AudioParameterBool> ("bypass", "Bypass", false)
    })
{
    // CLEAN: Only initialize ML classifier
    mlFootstepClassifier = std::make_unique<MLFootstepClassifier>();
    
    // Try to load ML model
    juce::File executableFile = juce::File::getSpecialLocation(juce::File::currentExecutableFile);
    juce::File modelFile = executableFile.getParentDirectory()
                              .getChildFile("models")
                              .getChildFile("footstep_detector_realistic.tflite");
    
    // Alternative paths for different deployment scenarios
    if (!modelFile.existsAsFile()) {
        modelFile = executableFile.getParentDirectory()
                       .getParentDirectory()
                       .getChildFile("Resources")
                       .getChildFile("models")
                       .getChildFile("footstep_detector_realistic.tflite");
    }
    
    if (!modelFile.existsAsFile()) {
        modelFile = juce::File::getCurrentWorkingDirectory()
                       .getChildFile("models")
                       .getChildFile("footstep_detector_realistic.tflite");
    }
    
    // Load ML model
    if (mlFootstepClassifier->loadModel(modelFile.getFullPathName().toStdString())) {
        std::cout << "âœ… ML Footstep Detector Loaded Successfully!" << std::endl;
        std::cout << "   ðŸ¤– Using 97.5% accurate trained model" << std::endl;
        std::cout << "   ðŸ“ Model path: " << modelFile.getFullPathName() << std::endl;
    } else {
        std::cout << "âš ï¸  Model file not found, using pre-trained weights" << std::endl;
        std::cout << "   ðŸ¤– Still using ML detection with embedded weights" << std::endl;
    }
    
    // Initialize EQ filters for stereo
    lowShelfFilter.resize(2);
    midShelfFilter.resize(2);  
    highShelfFilter.resize(2);
    
    for (auto& filter : lowShelfFilter) {
        filter.reset();
    }
    for (auto& filter : midShelfFilter) {
        filter.reset();
    }
    for (auto& filter : highShelfFilter) {
        filter.reset();
    }
    
    // Get parameter pointers
    sensitivityParam = parameters.getRawParameterValue ("sensitivity");
    enhancementParam = parameters.getRawParameterValue ("enhancement");
    bypassParam = parameters.getRawParameterValue ("bypass");
    
    std::cout << "ðŸš€ ML-Powered FootstepDetector Initialized!" << std::endl;
    std::cout << "ðŸš€ ANTI-CRACKLING FIXES LOADED!" << std::endl;
    std::cout << "   ðŸŽšï¸  Subtle enhancement: 1.0x to 1.4x (footsteps only)" << std::endl;
    std::cout << "   ðŸŽ›ï¸  Gentle EQ: 3.7dB total (was 10.5dB)" << std::endl;
    std::cout << "   ðŸ”Š Gain compensation: 0.7x factor applied" << std::endl;
    std::cout << "   ðŸ“ˆ Smoother envelopes: slower attack/release" << std::endl;
    std::cout << "   ðŸ›¡ï¸  Gentle limiting: starts at 0.7 (was 0.9)" << std::endl;
    std::cout << "   âœ… NO REDUCTION: Audio passes through unchanged when no footsteps" << std::endl;
}


FootstepDetectorAudioProcessor::~FootstepDetectorAudioProcessor()
{
}

const juce::String FootstepDetectorAudioProcessor::getName() const
{
#ifdef JucePlugin_Name
    return JucePlugin_Name;
#else
    return "FootstepDetector";
#endif
}

bool FootstepDetectorAudioProcessor::acceptsMidi() const
{
    return false;
}

bool FootstepDetectorAudioProcessor::producesMidi() const
{
    return false;
}

bool FootstepDetectorAudioProcessor::isMidiEffect() const
{
    return false;
}

double FootstepDetectorAudioProcessor::getTailLengthSeconds() const
{
    return 0.0;
}

int FootstepDetectorAudioProcessor::getNumPrograms()
{
    return 1;
}

int FootstepDetectorAudioProcessor::getCurrentProgram()
{
    return 0;
}

void FootstepDetectorAudioProcessor::setCurrentProgram(int index)
{
    (void)index;
}

const juce::String FootstepDetectorAudioProcessor::getProgramName(int index)
{
    (void)index;
    return {};
}

void FootstepDetectorAudioProcessor::changeProgramName(int index, const juce::String& newName)
{
    (void)index;
    (void)newName;
}

void FootstepDetectorAudioProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    // CLEAN: Only prepare ML classifier
    if (mlFootstepClassifier != nullptr)
    {
        mlFootstepClassifier->prepare(sampleRate, samplesPerBlock);
        std::cout << "âœ… ML classifier prepared for " << sampleRate << " Hz" << std::endl;
    }
    else
    {
        std::cerr << "âŒ CRITICAL: ML classifier is null! Plugin cannot function." << std::endl;
        return;
    }
    
    juce::dsp::ProcessSpec spec;
    spec.sampleRate = sampleRate;
    spec.maximumBlockSize = samplesPerBlock;
    spec.numChannels = 2;

    // Calculate hold duration (200ms for natural footstep decay)
    footstepHoldDuration = static_cast<int>(sampleRate * 0.2);
    
    // SUBTLE EQ for ML-detected footsteps (gentle enhancement to prevent crackling)
    for (auto& filter : lowShelfFilter) {
        filter.prepare(spec);
        filter.reset();
        filter.coefficients = juce::dsp::IIR::Coefficients<float>::makeLowShelf(
            sampleRate,
            180.0f,  // Low frequency footstep thump
            0.8f,    // Q factor
            1.5f     // SUBTLE: 1.5dB = 1.19x (was 4dB)
        );
    }

    for (auto& filter : midShelfFilter) {
        filter.prepare(spec);
        filter.reset();
        filter.coefficients = juce::dsp::IIR::Coefficients<float>::makePeakFilter(
            sampleRate,
            300.0f,  // Mid frequency footstep clarity
            0.7f,    // Q factor
            1.2f     // SUBTLE: 1.2dB = 1.14x (was 3.5dB)
        );
    }

    for (auto& filter : highShelfFilter) {
        filter.prepare(spec);
        filter.reset();
        filter.coefficients = juce::dsp::IIR::Coefficients<float>::makePeakFilter(
            sampleRate,
            450.0f,  // High frequency footstep definition
            0.6f,    // Q factor
            1.0f     // SUBTLE: 1dB = 1.12x (was 3dB)
        );
    }
    
    std::cout << "ðŸŽ›ï¸  SUBTLE EQ prepared for ML-detected footsteps" << std::endl;
    std::cout << "   ðŸ”Š Low shelf (180Hz): +1.5dB boost (was +4dB)" << std::endl;
    std::cout << "   ðŸ”Š Mid peak (300Hz): +1.2dB boost (was +3.5dB)" << std::endl;
    std::cout << "   ðŸ”Š High peak (450Hz): +1dB boost (was +3dB)" << std::endl;
    std::cout << "   âœ… Total EQ gain: ~3.7dB (was ~10.5dB)" << std::endl;
}


juce::AudioProcessorEditor* FootstepDetectorAudioProcessor::createEditor()
{
    // Return generic editor for EqualizerAPO compatibility
    return new juce::GenericAudioProcessorEditor(*this);
}

void FootstepDetectorAudioProcessor::releaseResources()
{
}

bool FootstepDetectorAudioProcessor::isBusesLayoutSupported(const BusesLayout& layouts) const
{
    if (layouts.getMainOutputChannelSet() != juce::AudioChannelSet::mono()
     && layouts.getMainOutputChannelSet() != juce::AudioChannelSet::stereo())
        return false;

    if (layouts.getMainOutputChannelSet() != layouts.getMainInputChannelSet())
        return false;

    return true;
}

void FootstepDetectorAudioProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages)
{
    juce::ScopedLock lock(processingLock);
    
    if (isProcessing) return;
    isProcessing = true;
    
    juce::ScopedNoDenormals noDenormals;
    
    auto totalNumInputChannels = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();

    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());

    float sensitivity = juce::jlimit(0.0f, 1.0f, sensitivityParam->load());
    float enhancement = juce::jlimit(1.0f, 1.4f, enhancementParam->load());
    bool bypass = bypassParam->load() > 0.5f;
    
    // DEBUG: Print parameter values periodically - less frequent
    static int debugCounter = 0;
    debugCounter++;
    if (debugCounter % (44100 * 3) == 0) { // Every ~3 seconds at 44.1kHz
        std::cout << "ðŸ”§ PLUGIN DEBUG - Sensitivity: " << sensitivity 
                  << " | Enhancement: " << enhancement << " (SUBTLE: max 1.4x, was 2.0x)"
                  << " | Bypass: " << (bypass ? "ON" : "OFF") << std::endl;
        
        if (mlFootstepClassifier) {
            mlFootstepClassifier->printDebugStats();
        }
    }
    
    if (bypass) {
        isProcessing = false;
        return;
    }

    // CLEAN: Only check ML classifier
    if (!mlFootstepClassifier) {
        std::cerr << "âŒ ML classifier unavailable, bypassing processing" << std::endl;
        isProcessing = false;
        return;
    }

    for (int channel = 0; channel < totalNumInputChannels; ++channel)
    {
        auto* channelData = buffer.getWritePointer(channel);

        for (int sample = 0; sample < buffer.getNumSamples(); ++sample)
        {
            float inputSample = channelData[sample];
            
            if (std::isnan(inputSample) || std::isinf(inputSample))
            {
                channelData[sample] = 0.0f;
                continue;
            }
            
            // CLEAN: Only ML detection path
            bool isFootstep = mlFootstepClassifier->detectFootstep(inputSample, sensitivity);
            
            // ML-ENHANCED PROCESSING
            if (isFootstep)
            {
                // FOOTSTEP: Apply full enhancement
                targetAmplification = enhancement; // 1.0 to 1.4x
                holdSamples = footstepHoldDuration;
                inHoldPhase = true;
            }
            else if (inHoldPhase && holdSamples > 0)
            {
                // HOLD PHASE: Gradual decay
                float decayRatio = float(holdSamples) / footstepHoldDuration;
                targetAmplification = 1.0f + (enhancement - 1.0f) * decayRatio;
                holdSamples--;
            }
            else if (inHoldPhase && holdSamples <= 0)
            {
                // END HOLD: Return to normal
                targetAmplification = 1.0f; // NO REDUCTION: just pass through
                inHoldPhase = false;
            }
            else
            {
                // NOT FOOTSTEP: Pass through unchanged
                targetAmplification = 1.0f; // NO REDUCTION: just pass through
            }
            
            // SMOOTH envelope - prevent harsh jumps
            if (currentAmplification < targetAmplification)
            {
                float attackRate = isFootstep ? envelopeAttack * 1.8f : envelopeAttack; // GENTLE: 1.8x (was 3.0x)
                currentAmplification += (targetAmplification - currentAmplification) * attackRate;
            }
            else if (currentAmplification > targetAmplification)
            {
                currentAmplification += (targetAmplification - currentAmplification) * envelopeRelease;
            }
            
            // Apply processing with proper gain staging
            float processedSample = inputSample;
            
            // DEBUG: Track amplification values occasionally
            static int ampDebugCounter = 0;
            ampDebugCounter++;
            if (ampDebugCounter % 22050 == 0 && currentAmplification > 1.05f) { // Every ~0.5 seconds
                std::cout << "ðŸ”Š AMPLIFICATION DEBUG - Current: " << currentAmplification 
                          << " | Target: " << targetAmplification 
                          << " | Compensated: " << (currentAmplification * 0.7f) 
                          << " | Hold phase: " << (inHoldPhase ? "YES" : "NO") << std::endl;
            }
            
            if (currentAmplification > 1.05f) {
                // FOOTSTEP ENHANCEMENT: Apply subtle EQ first, then gentle amplification
                processedSample = applyMultiBandEQ(inputSample, channel);
                
                // GAIN COMPENSATION: Reduce amplification to account for EQ gain
                float compensatedAmplification = currentAmplification * 0.7f; // Compensate for EQ gain
                processedSample *= compensatedAmplification;
                
                // GENTLE limiting - start limiting earlier and more gradually
                if (std::abs(processedSample) > 0.7f) {
                    float sign = (processedSample >= 0.0f) ? 1.0f : -1.0f;
                    float abs_amp = std::abs(processedSample);
                    // Smooth soft limiting curve
                    float limitedAmp = 0.7f + (abs_amp - 0.7f) * 0.2f; // Gentle limiting ratio
                    processedSample = sign * limitedAmp;
                }
            }
            // REMOVED: No noise reduction - when not enhancing, just pass through unchanged
            
            // FINAL safety limiting
            channelData[sample] = juce::jlimit(-0.95f, 0.95f, processedSample);
        }
    }
    
    isProcessing = false;
}

// float FootstepDetectorAudioProcessor::applySaturation(float sample)
// {
//     // FIXED: Gentle soft limiting instead of aggressive saturation
//     float limited = sample;
    
//     // Soft knee compression above 0.7
//     if (std::abs(sample) > 0.7f) {
//         float sign = (sample >= 0.0f) ? 1.0f : -1.0f;
//         float abs_sample = std::abs(sample);
        
//         // Gentle soft limiting curve
//         limited = sign * (0.7f + (abs_sample - 0.7f) * 0.3f);
//     }
    
//     // REMOVED: Extra 1.5x boost that was causing clipping
//     return juce::jlimit(-0.95f, 0.95f, limited); // Hard limit at Â±0.95
// }


// Simple EQ-based footstep enhancement
float FootstepDetectorAudioProcessor::applyFootstepEQ(float sample, int channel)
{
    if (channel < 0 || channel >= lowShelfFilter.size()) {
        return sample;
    }
    
    // Apply low shelf filter to boost footstep frequencies (50-250Hz)
    float eqSample = lowShelfFilter[channel].processSample(sample);
    
    return eqSample;
}

float FootstepDetectorAudioProcessor::applyMultiBandEQ(float sample, int channel)
{
    if (channel < 0 || channel >= lowShelfFilter.size()) {
        return sample;
    }
    
    // FIXED: Apply filters in series (not parallel) to prevent phase issues
    float enhanced = sample;
    
    // Apply low shelf filter
    enhanced = lowShelfFilter[channel].processSample(enhanced);
    
    // Apply mid peak filter
    enhanced = midShelfFilter[channel].processSample(enhanced);
    
    // Apply high peak filter  
    enhanced = highShelfFilter[channel].processSample(enhanced);
    
    // GAIN COMPENSATION: Slightly reduce overall gain to prevent buildup
    enhanced *= 0.85f; // Compensate for cumulative EQ gain
    
    return enhanced;
}

bool FootstepDetectorAudioProcessor::hasEditor() const
{
    return true;
}

void FootstepDetectorAudioProcessor::getStateInformation(juce::MemoryBlock& destData)
{
    // FIXED: Use AudioProcessorValueTreeState for proper state management
    auto state = parameters.copyState();
    std::unique_ptr<juce::XmlElement> xml (state.createXml());
    copyXmlToBinary (*xml, destData);
}

void FootstepDetectorAudioProcessor::setStateInformation(const void* data, int sizeInBytes)
{
    // FIXED: Use AudioProcessorValueTreeState for proper state management
    std::unique_ptr<juce::XmlElement> xmlState (getXmlFromBinary (data, sizeInBytes));
    
    if (xmlState.get() != nullptr)
        if (xmlState->hasTagName (parameters.state.getType()))
            parameters.replaceState (juce::ValueTree::fromXml (*xmlState));
}

// ADD THESE MISSING PARAMETER METHODS:

float FootstepDetectorAudioProcessor::getParameter(int index)
{
    switch (index) {
        case 0: return sensitivityParam->load();
        case 1: return (enhancementParam->load() - 1.0f) / 0.4f; // SUBTLE: adjusted for 1.0-1.4 range
        case 2: return bypassParam->load(); // FIXED: Now case 2
        default: return 0.0f;
    }
}


void FootstepDetectorAudioProcessor::setParameter(int index, float value)
{
    switch (index) {
        case 0: sensitivityParam->store(juce::jlimit(0.0f, 1.0f, value)); break;
        case 1: enhancementParam->store(1.0f + (juce::jlimit(0.0f, 1.0f, value) * 0.4f)); break; // SUBTLE: 1.0 to 1.4x (was 1.0x)
        case 2: bypassParam->store(value > 0.5f ? 1.0f : 0.0f); break; // FIXED: Now case 2
    }
}


const juce::String FootstepDetectorAudioProcessor::getParameterName(int index)
{
    switch (index) {
        case 0: return "Sensitivity";
        case 1: return "Enhancement";
        case 2: return "Bypass";
        default: return {};
    }
}

const juce::String FootstepDetectorAudioProcessor::getParameterText(int index)
{
    switch (index) {
        case 0: return juce::String(sensitivityParam->load(), 2);
        case 1: return juce::String(enhancementParam->load(), 1) + "x";
        case 2: return bypassParam->load() > 0.5f ? "On" : "Off";
        default: return {};
    }
}

// ADD: EqualizerAPO compatibility method
void FootstepDetectorAudioProcessor::getEditorSize(int& width, int& height)
{
    width = 400;
    height = 300;
}

namespace juce
{
    float JUCE_CALLTYPE handleManufacturerSpecificVST2Opcode (int, long long, void*, float)
    {
        return 0.0f; // Return 0 for unsupported opcodes
    }
}

juce::AudioProcessor* JUCE_CALLTYPE createPluginFilter()
{
    return new FootstepDetectorAudioProcessor();
}
